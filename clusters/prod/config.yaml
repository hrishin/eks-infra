node_groups:
  # Core compute nodes for general workloads
  core:
    instance_types: ["z1d.2xlarge"]
    desired_size: 2
    min_size: 2
    max_size: 4
    disk_size: 20
    ami_id: "ami-060bb37b943ff8d8e"
    ami_type: "CUSTOM"
    labels:
      node-type: "core"
      workload: "system"
      environment: "production"
    taints:
      - key: "node-type"
        value: "core"
        effect: "NoSchedule"

  # # G4 instances - General purpose GPU instances with T4 (more widely available)
  # g4-training:
  #   instance_types: ["g4dn.xlarge", "g4dn.2xlarge"]
  #   desired_size: 1
  #   min_size: 0
  #   max_size: 3
  #   disk_size: 50
  #   ami_id: "ami-060bb37b943ff8d8e"
  #   ami_type: "CUSTOM"
  #   availability_zones: ["eu-west-2a", "eu-west-2c"]  # Exclude eu-west-2b due to g4dn.xlarge capacity issues
  #   labels:
  #     node-type: "gpu"
  #     workload: "ml-training"
  #     environment: "production"
  #     accelerator: "nvidia-t4"
  #     gpu-type: "g4"
  #   taints:
  #     - key: "nvidia.com/gpu"
  #       value: "true"
  #       effect: "NoSchedule"
  #     - key: "workload"
  #       value: "ml-training"
  #       effect: "NoSchedule"
